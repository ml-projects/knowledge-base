{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group6-Venky-M0_MP1_Data_Munging (Ungraded).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7rc1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ml-projects/knowledge-base/blob/master/Group6_Venky_M0_MP1_Data_Munging_(Ungraded).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUUu9l_JfJ92"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "\n",
        "##  A program by IISc and TalentSprint\n",
        "\n",
        "### Mini Project Notebook 1 : Data munging\n",
        "\n",
        "(Ungraded Mini-Project)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3yrUc-XrLS"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nljJR6CwfZN_"
      },
      "source": [
        "\n",
        "\n",
        "At the end of the experiment, you will be able to\n",
        "\n",
        "\n",
        "* understand the requirements for a “clean” dataset, ready for use in statistical analysis.\n",
        "\n",
        "* use Python libraries like Pandas, Numpy, and Matplotlib to perform the  data-preprocessing steps accordingly.\n",
        "\n",
        "* derive meaningful insights from the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EqvTSjZZIUE"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZX_NxQHZLu_"
      },
      "source": [
        "The dataset chosen for this experiment is **play store** dataset which is  publicly available and created with this [methodology](https://nycdatascience.com/blog/student-works/google-play-store-everything-that-you-need-to-know-about-the-android-market/)  \n",
        "\n",
        "This dataset consists of 10841 records. Each record is made up of 13 fields.\n",
        "\n",
        "**For example**, one record consist of App, Category, Rating, Reviews, Size, Installs, Type, Price, Content Rating, Genres, Last Updated, Current Ver, and Android Ver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3vgcWwOF2cK"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VTtVENRXo7i"
      },
      "source": [
        "Before we can derive any meaningful insights from the Play Store data, it is essential to pre-process the data and make it suitable for further analysis. This pre-processing step forms a major part of data wrangling (or data munging) and ensures better quality data. It consists of the transformation and mapping of data from a \"raw\" data form into another format so that it is more valuable for a variety of downstream purposes such as analytics. Data analysts typically spend a sizeable amount of time in the process of data wrangling, compared to the actual analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CgkmzMOXo7j"
      },
      "source": [
        "After data munging is performed, several actionable insights can be derived from the Play Store apps data. Such insights could help to unlock the enormous potential to drive app-making businesses to success."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwmmvQnv3mLM",
        "cellView": "form"
      },
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/Datasets/googleplaystore.csv\n",
        "print(\"Data downloaded successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmOJDVdp9PYo"
      },
      "source": [
        "#### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DrVCIg54LZp"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATAFILE = \"googleplaystore.csv\"\n",
        "#load playstore data into a pandas data frame\n",
        "data = pd.read_csv(DATAFILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li5KS0i3pQqq"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP11Ov2mXo7p"
      },
      "source": [
        "There are different steps involved in Data Preprocessing. These steps are as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NwZ6jBHXo7q"
      },
      "source": [
        "    1. Data Cleaning → In this step the primary focus is on\n",
        "        -Handling missing data\n",
        "        -Handling noisy data\n",
        "        -Detection and removal of outliers\n",
        "    \n",
        "    2. Data Integration → This process is used when data is gathered from various data sources\n",
        "    and data are combined to form consistent data. This data after performing cleaning is used\n",
        "    for analysis.\n",
        "    \n",
        "    3. Data Transformation → In this step we will convert the raw data into a specified format\n",
        "    according to the need of the model we are building. There are many options used for\n",
        "    transforming the data as below:\n",
        "        -Normalization\n",
        "        -Aggregation\n",
        "        -Generalization\n",
        "        \n",
        "    4. Data Reduction → After data transformation and scaling the redundancy within the data\n",
        "    is removed and efficiently organizing the data is performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edt4IHsO4lua"
      },
      "source": [
        "### Task 1: Data Cleaning\n",
        "\n",
        "* Check whether there are any null values and figure out how you want to handle them? \n",
        "  \n",
        "    **Hint:** isnan(), dropna(), fillna()\n",
        "* If there is any duplication of a record, how would you like to handle it?\n",
        "\n",
        "    Hint: [drop_duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
        "\n",
        "* Are there any non-English apps? And how to filter them?\n",
        "\n",
        "* In the size column, multiply 1,000,000 with M in the cell and multiply by 1000 if we have K in the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jbfxgnEUFvZ"
      },
      "source": [
        "data.dropna(inplace=True)\n",
        "data.drop_duplicates(inplace=True)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzwoJW8LHkA3"
      },
      "source": [
        "import regex as re\n",
        "\n",
        "def remove_emoji(text:str) -> str:\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text).strip()\n",
        "\n",
        "def isEnglish(appname: str) -> bool:\n",
        "  return remove_emoji(appname).isascii()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g029AMY8nBfP"
      },
      "source": [
        "data['isAppNameEng'] = data.App.apply(isEnglish)\n",
        "data = data[(data.isAppNameEng == True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqj9-rDPD8GP"
      },
      "source": [
        "#@title Transforming by vector way\n",
        "mask = data.Size.str.upper().str.endswith('M')\n",
        "data.loc[mask,'Size_new'] = data[mask].Size.str[:-1].astype(float) * 100000 \n",
        "mask = data.Size.str.upper().str.endswith('K')\n",
        "data.loc[mask,'Size_new'] = data[mask].Size.str[:-1].astype(float) * 1000\n",
        "#data.fillna(value={'Size_new': 0}, inplace=True)\n",
        "data.dropna(inplace=True)\n",
        "data['Size'] = data['Size_new']\n",
        "data.drop(labels=['Size_new'], axis=1, inplace=True)\n",
        "data[data.Size.isna()].head(20)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObNw--LAM8d1"
      },
      "source": [
        "#remove apps with in valid size\n",
        "#data = data[(data.Size > 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYW9U3u5NI0-"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy4-aL9QHF9K"
      },
      "source": [
        "\n",
        "data.loc[:,\"Installs\"] = data.Installs.str.replace(',','').str.replace('+','').astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1G-D1y3VMDC"
      },
      "source": [
        "data.loc[:,\"Price\"] = data.Price.str.replace(',','').str.replace('$','').astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrPzlHc4-zIR"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFgtC_jCpJL1"
      },
      "source": [
        "### Task 2: Perform the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QQ2WUQX9XYy"
      },
      "source": [
        "##### Exercise 1: Find the number of apps in various categories by using an appropriate plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deofcwfonL26"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtJUMgOFXGt3"
      },
      "source": [
        "# dataframe to hold count by category\n",
        "catdf = data.groupby(\"Category\").agg(num_of_apps = ('App','nunique'))\n",
        "sns.set_style(\"darkgrid\")\n",
        "catdf.plot(kind=\"bar\",figsize=(20,6),title=\"Number of Applications by Category\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS68279nnIhZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzzEnMv25vGn"
      },
      "source": [
        "##### Exercise 2: Explore the distribution of free and paid apps across different categories\n",
        "\n",
        "**Hint:** Stacked Bar Chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzxR7Gj4Rrbw"
      },
      "source": [
        "# Group by Category and Type, use unique count aggregation on column \"APP\"\n",
        "TypeDistrDF = data.groupby(by=[\"Category\",\"Type\"]).agg(num_of_apps = ('App','nunique')).reset_index()\n",
        "TypeDistrDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZhT6XtTo9r6"
      },
      "source": [
        "# Transpose data\n",
        "TypeDistrDF= TypeDistrDF.pivot(index='Category',columns = 'Type',values='num_of_apps').fillna(value =0 )\n",
        "TypeDistrDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQJnCOm2pCu9"
      },
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "TypeDistrDF.plot(kind=\"bar\",stacked=True,figsize=(20,5),title=\"App Distribution by Type and Category\",ylabel=\"Count of Apps\") # by default index will be plotted on x-axis\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFNIQ4dj59Ep"
      },
      "source": [
        "##### Exercise 3: Represent the distribution of app rating on a scale of 1-5 using an appropriate plot\n",
        "\n",
        "**Hint:** histogram / strip plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZDWxb_JRtBl"
      },
      "source": [
        "sns.set_style(\"white\")\n",
        "data.hist(column='Rating',bins = 5,grid=False,figsize=(20,5),align='mid',histtype='stepfilled',label=None)\n",
        "plt.title(\"Distribution of Applications Rating\")\n",
        "plt.ylabel(\"Number of Apps\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBreBsQ7Vqi0"
      },
      "source": [
        "##### Exercise 4: Identify outliers of the rating column by plotting the boxplot category wise and Handle them.\n",
        "\n",
        "**Hint:** Removing Outliers using z-score, quantile [link](https://kanoki.org/2020/04/23/how-to-remove-outliers-in-python/) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-272Rhl96G6"
      },
      "source": [
        "outlierratingsdf = data.loc[:,{\"Category\",\"Rating\"}]\n",
        "outlierratingsdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehVoOe9ARv0w"
      },
      "source": [
        "outlierratingsdf.boxplot(column='Rating',by='Category',figsize=(10,10),vert= False,patch_artist=True)\n",
        "plt.title(\"Box Plot for Outlier Identification by Categories\")\n",
        "plt.ylabel(\"Category\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiOWt855DsZ8"
      },
      "source": [
        "##### Exercise 5: Plot the barplot of all the categories indicating no. of installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3LW5CejRyBc"
      },
      "source": [
        "sns.set_style('darkgrid')\n",
        "installsDF = data.groupby(\"Category\").agg(num_of_installs = ('Installs','sum'))\n",
        "installsDF.plot(kind=\"bar\",figsize=(20,10),logy='sym',ylabel='Number of Installs',title='Number of Installations by Category')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLNboJI1bDhL"
      },
      "source": [
        "## Insights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boBhK2SdGXlW"
      },
      "source": [
        "### Task 3: Derive the below insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtVLkGB_ANwf"
      },
      "source": [
        "##### Exercise 1: Does the price correlate with the size of the app?\n",
        "\n",
        "  **Hint:** plot the scatterplot of `Size` and `Price`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDhPtmBCJC41"
      },
      "source": [
        "\n",
        "size_price_df = data.loc[:,{\"Size\",\"Price\"}]\n",
        "size_price_df.plot(kind=\"scatter\",x=\"Price\",y=\"Size\",figsize=(20,10),logy='sym',title=\"Correlation between size and price of Apps\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYUVDBaycwlB"
      },
      "source": [
        "# Compute the correlation matrix\n",
        "corr = size_price_df.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "print(corr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb861WejndKI"
      },
      "source": [
        "##### Exercise 2: Find the popular app categories based on rating and no. of installs\n",
        "\n",
        "**Hint:** [df.groupby.agg()](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.core.groupby.DataFrameGroupBy.agg.html); Taking the average rating could be another approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWftl4eC2jNU"
      },
      "source": [
        "popularAppsDF = data.groupby(\"Category\").agg(avg_rating = ('Rating','mean'),num_of_installs = ('Installs','sum')).sort_values('avg_rating',ascending=False)\n",
        "popularAppsDF.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kksy2sD4CMKQ"
      },
      "source": [
        "##### Exercise 3: How many apps are produced in each year category-wise ?\n",
        "\n",
        "  * Create a `Year` column by slicing the values of `Last Updated` column and find the Year with most no. of apps produced \n",
        "\n",
        "    **For example**, slice the year `2017` from `February 8, 2017` \n",
        "\n",
        "  * Find the categories which have a consistent rating in each year\n",
        "\n",
        "      **Hint:** `sns.countplot`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpnlYfHCO3P"
      },
      "source": [
        "data['Year']=data['Last Updated'].map(lambda x: x[-4:])\n",
        "appsyearwisedf = data.groupby(by=[\"Year\",\"Category\"]).agg(num_of_apps = ('App','nunique')).reset_index()\n",
        "appsyearwisedf.pivot(index=\"Category\",columns=\"Year\",values=\"num_of_apps\").fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85qdiRnDbpQE"
      },
      "source": [
        "ratingdf = data.groupby(by=[\"Year\",\"Category\"]).agg(avg_rating=('Rating','mean')).reset_index()\n",
        "ratingdf[\"avg_rating\"]= ratingdf[\"avg_rating\"].map(lambda x:round(x,2))\n",
        "ratingdf= ratingdf.pivot(index=\"Category\",columns=\"Year\",values=\"avg_rating\").fillna(0)\n",
        "ratingdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkseNl0qQ-HB"
      },
      "source": [
        "ratingdf.plot(kind=\"bar\",figsize=(100,10),title=\"Ratings of categories years wise\",ylabel=\"Average Rating\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnhRhfWadnGK"
      },
      "source": [
        "##### Exercise 4: Identify the highest paid apps with a good rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LmV1w_JdvRg"
      },
      "source": [
        "data[\"Price_numeric\"] = data['Price'].apply(lambda price : float(price.replace('$',\"\")))\n",
        "data.sort_values(by=\"Price_numeric\",ascending=False,inplace=True)\n",
        "highestpaidapps = data.head(20)[(data.Rating>4)]\n",
        "highestpaidapps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSCEb0GX5-d1"
      },
      "source": [
        "##### Exercise 5: Are the top-rated apps genuine ? How about checking reviews count of top-rated apps ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8kGpmMmx7HI"
      },
      "source": [
        "topratedapps = data[(data.Rating==5)].sort_values(by=\"Reviews\")\n",
        "topratedapps.iloc[:,:6]\n",
        "# Top Rated Apps are not genuine as the review count is less than 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXQfqIixzC4_"
      },
      "source": [
        "##### Exercise 6: If the number of reviews of an app is very low, what could be the reason for its top-rating ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_gj_f-UzGEF"
      },
      "source": [
        "#From the above dataset, it infers despite many downloads, ratings were not given by everyone. So,if few members from the development team gives 5 then rating will be 5"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}